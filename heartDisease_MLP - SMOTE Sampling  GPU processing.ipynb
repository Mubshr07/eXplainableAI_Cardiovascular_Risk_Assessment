{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_masked_model.py:346: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\utils\\_masked_model.py:365: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\maskers\\_tabular.py:184: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\maskers\\_tabular.py:195: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplot\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "import subprocess\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "   \n",
    "import csv\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist \n",
    " \n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle \n",
    "\n",
    "from shap import TreeExplainer, Explanation\n",
    "from shap.plots import waterfall\n",
    "import shap\n",
    "print(shap.__version__)\n",
    "\n",
    "\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import random\n",
    "\n",
    "import dalex as dx \n",
    "\n",
    "from tabulate import tabulate \n",
    " \n",
    "# Define custom metrics\n",
    "recall = Recall()\n",
    "precision = Precision() \n",
    "auc = AUC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fileData: (37079, 40)\n",
      "Column Headings: Index(['Gender', 'Age', 'X60-sec-pulse', 'Systolic', 'Diastolic', 'Weight',\n",
      "       'Height', 'Body-Mass-Index', 'White-Blood-Cells', 'Lymphocyte',\n",
      "       'Monocyte', 'Eosinophils', 'Basophils', 'Red-Blood-Cells', 'Hemoglobin',\n",
      "       'Platelet-count', 'Segmented-Neutrophils', 'Hematocrit', 'Albumin',\n",
      "       'ALP', 'AST', 'ALT', 'Cholesterol', 'Creatinine', 'Glucose', 'Iron',\n",
      "       'LDH', 'Phosphorus', 'Bilirubin', 'Protein', 'Uric.Acid',\n",
      "       'Triglycerides', 'Total-Cholesterol', 'HDL', 'Glycohemoglobin',\n",
      "       'Moderate-work', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke',\n",
      "       'CoronaryHeartDisease'],\n",
      "      dtype='object')\n",
      "Number of Records: 37079\n",
      "\n",
      "Number of Missing Values: 0\n",
      "Number of duplicate records removed: 0\n",
      "Shape of fileData: (37079, 40)\n",
      "Shape of fileData End: (37079, 40)\n",
      "\n",
      "\n",
      "columns of x:: 38 \n",
      "\n",
      " and features of X: Index(['Age', 'X60-sec-pulse', 'Systolic', 'Diastolic', 'Weight', 'Height',\n",
      "       'Body-Mass-Index', 'White-Blood-Cells', 'Lymphocyte', 'Monocyte',\n",
      "       'Eosinophils', 'Basophils', 'Red-Blood-Cells', 'Hemoglobin',\n",
      "       'Platelet-count', 'Segmented-Neutrophils', 'Hematocrit', 'Albumin',\n",
      "       'ALP', 'AST', 'ALT', 'Cholesterol', 'Creatinine', 'Glucose', 'Iron',\n",
      "       'LDH', 'Phosphorus', 'Bilirubin', 'Protein', 'Uric.Acid',\n",
      "       'Triglycerides', 'Total-Cholesterol', 'HDL', 'Glycohemoglobin',\n",
      "       'Moderate-work', 'Diabetes', 'Blood-Rel-Diabetes', 'Blood-Rel-Stroke'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataSetIndex = 6\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "if(dataSetIndex == 0):\n",
    "    dataSetFilePath = \"./heartDisease/0_statLog_dataSet.csv\"\n",
    "    dataSetName = \"SateLog_DataSet\"\n",
    "elif (dataSetIndex == 1):\n",
    "    dataSetFilePath = \"./heartDisease/1_heart_statlog_cleveland_hungary_final.csv\"\n",
    "    dataSetName = \"ALL_StateLog_CleveLand_Hungary\"\n",
    "elif (dataSetIndex == 2):\n",
    "    dataSetFilePath = \"./heartDisease/2_cleveland.csv\"\n",
    "    dataSetName = \"Cleveland\"\n",
    "elif (dataSetIndex == 3):\n",
    "    dataSetFilePath = \"./heartDisease/3_framingham.csv\"\n",
    "    dataSetName = \"framingham\"\n",
    "elif (dataSetIndex == 4):\n",
    "    dataSetFilePath = \"./heartDisease/4_CardiacPrediction.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 5):\n",
    "    dataSetFilePath = \"./heartDisease/5_CardiacPredictionLessDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "elif (dataSetIndex == 6):\n",
    "    dataSetFilePath = \"./heartDisease/6_CardiacPredictionFewDimensions.xlsx\"\n",
    "    dataSetName = \"CardiacPrediction\"\n",
    "else:\n",
    "    dataSetFilePath = \"\"\n",
    "    dataSetName = \"\"\n",
    "\n",
    "if(dataSetIndex==4 or dataSetIndex==5 or dataSetIndex==6):\n",
    "    #fileData = pd.read_excel(dataSetFilePath, sheet_name='CoroHeartDis')\n",
    "    fileData = pd.read_excel(dataSetFilePath)\n",
    "else:\n",
    "    fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0]\n",
    "# Remove duplicate records based on all columns\n",
    "fileData.drop_duplicates(inplace=True)\n",
    "# Check the number of rows after removing duplicates\n",
    "num_rows_after = fileData.shape[0]\n",
    "# Print the number of duplicate records removed\n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    " \n",
    " # Preprocess Steps from the ChatGPT\n",
    "# 1. Handling Missing Values:\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))              \n",
    "#fileData.replace({'?': np.nan}).dropna().astype(float)\n",
    "#fileData = fileData.fillna(0) \n",
    "\n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score','AUC'], ]  \n",
    "\n",
    "\n",
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "X = X.drop('Gender', axis=1)  # Features\n",
    "#cols = ['Gender', 'Age','Annual-Family-Income', 'Cholesterol', 'Diabetes', 'Triglycerides', 'Red-Cell-Distribution-Width', 'X60-sec-pulse', 'Height', 'Albumin', 'Blood-Rel-Stroke', 'Blood-Rel-Diabetes', 'HDL', 'Moderate-work','Iron', 'Hemoglobin','Protein', 'SEQN'   ] \n",
    "#cols = ['Age','Gender','Blood-Rel-Stroke','Triglycerides','Blood-Rel-Diabetes','Cholesterol','Platelet-count','Diabetes','Albumin','Hemoglobin','Moderate-work','Diastolic','Protein','Height','X60-sec-pulse','White-Blood-Cells','Bilirubin','Hematocrit','HDL','Systolic' ] \n",
    "#X = fileData[cols]\n",
    "\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "dataSetResultDirectory = \"./\"\n",
    "dataSetResultDirectory += (\"DatasetResults_MLP_SMOTE_April_24\")\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    "\n",
    "dataSetName += \"_{}\".format(fileData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fileData: (37079, 40) , target Len:37079\n",
      "X: (37079, 38) , Y:(37079,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Column Name:: CoronaryHeartDisease \n",
      "\n",
      "\n",
      " X Train: Shape:: (56913, 38)\n",
      " X Test: Shape:: (14229, 38)\n",
      "Train DataSet Positive Class Records:: 28457\n",
      "Train DataSet Negative Class Records:: 28456\n",
      "Train DataSet Total Records:: 56913\n",
      "\n",
      "\n",
      "\n",
      "Test DataSet Positive Class Records:: 7114\n",
      "Test DataSet Negative Class Records:: 7115\n",
      "Test DataSet Total Records:: 14229\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "ada = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "  \n",
    "# Oversample the minority class using SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X, Y)  \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    " \n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(fileData.__dataframe__().column_names()[-1]))\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape))  \n",
    " \n",
    " \n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Train DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Train DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Train DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n",
    "print(\"\\n\\n\") \n",
    "\n",
    "\n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_test:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "print(\"Test DataSet Positive Class Records:: {}\".format(positiveClass)) \n",
    "print(\"Test DataSet Negative Class Records:: {}\".format(negativeClass)) \n",
    "print(\"Test DataSet Total Records:: {}\".format(positiveClass + negativeClass)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsForGraph = []\n",
    "columnsForGraph.clear()\n",
    "tableDataRow = []\n",
    "\n",
    "\n",
    "# Concatenate feature and target data for both training and testing sets\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "df_combined = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "columns = df_combined.__dataframe__().column_names() \n",
    "totalRecords = (df_combined.__dataframe__().num_rows())\n",
    "for column in columns:\n",
    "    singleColumnCount = df_combined[column].value_counts()\n",
    "    if(len(singleColumnCount) < 3):\n",
    "        #print('Column Name:{} -> total records:{}'.format(column, totalRecords ) )\n",
    "        #print('Number of classes:', len(singleColumnCount))\n",
    "        #print('Class distribution:')\n",
    "        #print(singleColumnCount)\n",
    "        #print(\"np Array: {}\".format(np.array(singleColumnCount)))\n",
    "        #print(\"index: 0: {} -> {} %\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100))\n",
    "        #print(\"index: 1: {} -> {} %\".format(np.array(singleColumnCount)[1], ( np.array(singleColumnCount)[1] /totalRecords) * 100))  \n",
    "        #print('---------------------------------------------------------------')\n",
    "        columnsForGraph.append(column)\n",
    " \n",
    "tableDataRow = [ ['Index', 'Column Name', 'Total Classes','Class A Records','Class B Records'], ]\n",
    "\n",
    "indexx = 1\n",
    "for column in columnsForGraph:\n",
    "    singleColumnCount = df_combined[column].value_counts()\n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(indexx)\n",
    "    singleRowInTable.append(column)\n",
    "    singleRowInTable.append(len(singleColumnCount))\n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[0], (np.array(singleColumnCount)[0] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    cellDataString = \"{} -> {:.2f}%\".format(np.array(singleColumnCount)[1], (np.array(singleColumnCount)[1] /totalRecords) * 100)\n",
    "    singleRowInTable.append((cellDataString)) \n",
    "    indexx += 1\n",
    "    tableDataRow.append(singleRowInTable) \n",
    "\n",
    " \n",
    "# Determine the number of rows in the table (excluding the header)\n",
    "num_rows = len(tableDataRow) + 1\n",
    "# Calculate the desired figure size based on the number of rows\n",
    "fig_width = 6  # Set the desired width of the figure\n",
    "fig_height = num_rows * 0.5  # Adjust the scaling factor to control the height\n",
    "\n",
    "fig, ax = mplot.subplots(figsize=(fig_width, fig_height)) \n",
    "table = mplot.table(cellText=tableDataRow, loc='center') \n",
    "\n",
    "table.auto_set_column_width(col=list(range(len(tableDataRow[0]))))\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12) \n",
    "table.scale(2.0, 2.0) \n",
    "\n",
    "dataSetString = \"Dataset:  {}, Total Records: {}, No. Features: {}\".format(dataSetName, totalRecords, df_combined.__dataframe__().num_columns())\n",
    "target =\"Target Column Name: {} , No of Classes: {}\".format(columns[-1], len(df_combined[columns[-1]].value_counts()))\n",
    "distributionOfTargetClassA =\"Class A Records: {} , {:.2f} %\".format(np.array(df_combined[columns[-1]].value_counts())[0], (np.array(df_combined[columns[-1]].value_counts())[0] /totalRecords) * 100)\n",
    "distributionOfTargetClassB =\"Class B Records: {} , {:.2f} %\".format(np.array(df_combined[columns[-1]].value_counts())[1], (np.array(df_combined[columns[-1]].value_counts())[1] /totalRecords) * 100)\n",
    "\n",
    "fig.text(-0.1, +0.10,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "fig.text(-0.1, +0.02,  target, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "fig.text(-0.1, -0.06,  distributionOfTargetClassA, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, -0.14,  distributionOfTargetClassB, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "\n",
    "remarks = \"You need to distribute the target class in equal number of records in training-set.\"\n",
    "#fig.text(-0.2, -0.15,  remarks, horizontalalignment='left', wrap=True ,fontsize=12, fontweight='bold' )   \n",
    " \n",
    "mplot.axis('off')\n",
    "mplot.title(f'Exploring Dataset after SMOTE' ,fontsize=16, fontweight='bold') \n",
    "picturePath = \"{}02.DataSet_analysis_After_dataAugmentation_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.savefig(picturePath,  dpi=300 )\n",
    "#mplot.show()\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (56913, 38)   and dType: 38\n",
      "X_train_scaler shape: (56913, 38)   and dType: float64\n",
      "X_test_scaler shape: (14229, 38)   and dType: float64\n",
      "y_train shape: (56913,)   and dType: int64\n",
      "y_test_scaler shape: (14229, 1)   and dType: float32\n",
      "features shape: (56913, 38)   and dType: float64\n",
      "target shape: (56913, 1)   and dType: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_normalized = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test_normalized = tf.keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test) \n",
    "# Our vectorized labels\n",
    "\n",
    "X_train_f32 = np.asarray(X_train).astype(np.float32)  #.astype('float32').reshape((-1,1))\n",
    "X_test_f32 = np.asarray(X_test).astype(np.float32)\n",
    "\n",
    "#y_train_scaler = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_scaler = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "# Separate features and target variable\n",
    "features = X_train_scaler # data.iloc[:, :-1]\n",
    "target = np.asarray(y_train).astype('float64').reshape((-1,1))  #data['CoronaryHeartDisease']\n",
    " \n",
    "print(\"X_train shape: {}   and dType: {}\".format(X_train.shape, len(X_train.columns)))\n",
    "print(\"X_train_scaler shape: {}   and dType: {}\".format(X_train_scaler.shape, X_train_scaler.dtype))\n",
    "print(\"X_test_scaler shape: {}   and dType: {}\".format(X_test_scaler.shape, X_test_scaler.dtype)) \n",
    "\n",
    "\n",
    "print(\"y_train shape: {}   and dType: {}\".format(y_train.shape, y_train.dtype))  \n",
    "print(\"y_test_scaler shape: {}   and dType: {}\".format(y_test_scaler.shape, y_test_scaler.dtype))  \n",
    "\n",
    "\n",
    "print(\"features shape: {}   and dType: {}\".format(features.shape, features.dtype))\n",
    "print(\"target shape: {}   and dType: {}\".format(target.shape, target.dtype)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Node: 19\n",
      "Number numberOfFeaturesForNNlayers of Node: 38\n",
      "GPU detected, using GPU for training.\n",
      "Epoch 1/10\n",
      "2277/2277 [==============================] - 33s 13ms/step - loss: 0.3075 - accuracy: 0.8724 - recall: 0.8915 - precision: 0.8587 - auc: 0.9396\n",
      "Epoch 2/10\n",
      "2277/2277 [==============================] - 28s 12ms/step - loss: 0.2349 - accuracy: 0.9084 - recall: 0.9396 - precision: 0.8844 - auc: 0.9630\n",
      "Epoch 3/10\n",
      "2277/2277 [==============================] - 30s 13ms/step - loss: 0.1876 - accuracy: 0.9285 - recall: 0.9540 - precision: 0.9078 - auc: 0.9752\n",
      "Epoch 4/10\n",
      "2277/2277 [==============================] - 35s 16ms/step - loss: 0.1568 - accuracy: 0.9433 - recall: 0.9647 - precision: 0.9251 - auc: 0.9815\n",
      "Epoch 5/10\n",
      "2277/2277 [==============================] - 35s 15ms/step - loss: 0.1332 - accuracy: 0.9518 - recall: 0.9693 - precision: 0.9366 - auc: 0.9863\n",
      "Epoch 6/10\n",
      "2277/2277 [==============================] - 32s 14ms/step - loss: 0.1145 - accuracy: 0.9596 - recall: 0.9730 - precision: 0.9475 - auc: 0.9896\n",
      "Epoch 7/10\n",
      "2277/2277 [==============================] - 31s 13ms/step - loss: 0.1019 - accuracy: 0.9646 - recall: 0.9771 - precision: 0.9534 - auc: 0.9914\n",
      "Epoch 8/10\n",
      "2277/2277 [==============================] - 28s 12ms/step - loss: 0.0905 - accuracy: 0.9696 - recall: 0.9807 - precision: 0.9594 - auc: 0.9930\n",
      "Epoch 9/10\n",
      "2277/2277 [==============================] - 28s 12ms/step - loss: 0.0827 - accuracy: 0.9723 - recall: 0.9811 - precision: 0.9641 - auc: 0.9941\n",
      "Epoch 10/10\n",
      "2277/2277 [==============================] - 29s 13ms/step - loss: 0.0734 - accuracy: 0.9751 - recall: 0.9830 - precision: 0.9678 - auc: 0.9953\n",
      "445/445 [==============================] - 4s 9ms/step - loss: 0.1505 - accuracy: 0.9544 - recall: 0.9827 - precision: 0.9300 - auc: 0.9846\n",
      "Test Accuracy: 0.9543889164924622\n",
      "Test Recall: 0.9827101230621338\n",
      "Test Precision: 0.9300252795219421\n",
      "Test AUC: 0.9845583438873291\n",
      "445/445 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95      7115\n",
      "         1.0       0.93      0.98      0.96      7114\n",
      "\n",
      "    accuracy                           0.95     14229\n",
      "   macro avg       0.96      0.95      0.95     14229\n",
      "weighted avg       0.96      0.95      0.95     14229\n",
      "\n",
      "Final Test Results:\n",
      "Accuracy: 0.9544\n",
      "Recall: 0.9827\n",
      "Precision: 0.9300\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Train and evaluate the model\n",
    "epochs = 10\n",
    "batch_size = 25\n",
    "\n",
    "history = 0\n",
    "model = 0\n",
    "binary_predictions = 0\n",
    "method = \"MLP\"\n",
    "\n",
    "numberOfFeaturesForNNlayers = X_train_scaler.shape[1]\n",
    "\n",
    "\n",
    "# Define the attention layer\n",
    "print(\"Number of Node: {}\".format(features.shape[1]//2))\n",
    "print(\"Number numberOfFeaturesForNNlayers of Node: {}\".format(numberOfFeaturesForNNlayers))\n",
    " \n",
    "\n",
    "def optimize_for_gpu(model):\n",
    "    # Leverage GPU if available\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"GPU detected, using GPU for training.\")\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy', Recall(), Precision(), AUC()])  # Add custom metrics\n",
    "    else:\n",
    "        print(\"GPU not detected, using CPU for training.\")\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy', Recall(), Precision(), AUC()])  # Add custom metrics\n",
    "\n",
    "def train_evaluate_model(X_train, X_test, y_train, y_test, model, epochs, batch_size):\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    # Evaluate on test set\n",
    "    loss, test_acc, test_recall, test_precision, test_auc = model.evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    print(\"Test Recall:\", test_recall)\n",
    "    print(\"Test Precision:\", test_precision)\n",
    "    print(\"Test AUC:\", test_auc)\n",
    "\n",
    "    # Print classification report (optional)\n",
    "    y_pred = model.predict(X_test)\n",
    "    binary_predictions = [1 if prob >= 0.5 else 0 for prob in y_pred]\n",
    "    # Now, you can use classification_report\n",
    "    print(classification_report(y_test, binary_predictions))\n",
    "\n",
    "    return test_acc, test_recall, test_precision, test_auc, history, binary_predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ... your data preprocessing and oversampling steps (replace placeholders)\n",
    "\n",
    "    # Define the model (consider hyperparameter tuning)\n",
    "    input_layer = tf.keras.layers.Input(numberOfFeaturesForNNlayers)\n",
    "\n",
    "    '''\n",
    "    # Traditional neural network part (adjust based on your analysis)\n",
    "    x = layers.Dense(X_train.shape[1] * 2, activation='relu')(input_layer)\n",
    "    x = layers.Dense(X_train.shape[1], activation='relu')(x)\n",
    "    x = layers.Dense(X_train.shape[1], activation='relu')(x)\n",
    "    x = layers.Dense(X_train.shape[1] // 2, activation='relu')(x)\n",
    "    '''\n",
    "    \n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers * 2, activation='relu')(input_layer)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers * 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers // 2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(numberOfFeaturesForNNlayers // 4, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    # Compile the model\n",
    "    #model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy', Recall(), Precision(), AUC()])  # Add custom metrics\n",
    "\n",
    "    # Optimize for GPU or CPU\n",
    "    optimize_for_gpu(model)\n",
    "    test_acc, test_recall, test_precision, test_auc, history, binary_predictions = train_evaluate_model(X_train_scaler, X_test_scaler, target, y_test_scaler, model, epochs, batch_size)\n",
    "\n",
    "    # Print final results and consider saving the model for future use\n",
    "    print(\"Final Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95      7115\n",
      "           1       0.93      0.98      0.96      7114\n",
      "\n",
      "    accuracy                           0.95     14229\n",
      "   macro avg       0.96      0.95      0.95     14229\n",
      "weighted avg       0.96      0.95      0.95     14229\n",
      "\n",
      "-------------=-=-=-=----------------\n",
      "[0.8724017143249512, 0.9084040522575378, 0.9285224676132202, 0.9432643055915833, 0.9518036246299744, 0.9595522880554199, 0.9646302461624146, 0.9695851802825928, 0.9722734689712524, 0.9751023650169373]\n",
      "-------------=-=-=-=----------------\n",
      "['              precision    recall  f1-score   support', '', '           0       0.98      0.93      0.95      7115', '           1       0.93      0.98      0.96      7114', '', '    accuracy                           0.95     14229', '   macro avg       0.96      0.95      0.95     14229', 'weighted avg       0.96      0.95      0.95     14229', '', '', '', ' Training accuracy:', '[0.8724017143249512, 0.9084040522575378, 0.9285224676132202, 0.9432643055915833, 0.9518036246299744, 0.9595522880554199, 0.9646302461624146, 0.9695851802825928, 0.9722734689712524, 0.9751023650169373]']\n"
     ]
    }
   ],
   "source": [
    "csvPath = \"{}Model_training_accuracy_and_evaluations_{}_{}_Epoch_{}.xlsx\".format(dataSetResultDirectory, method, dataSetName, epochs)\n",
    "\n",
    "# Create a new workbook\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active  # Get the active worksheet\n",
    "\n",
    "str22 = (classification_report(y_test, binary_predictions))\n",
    " \n",
    "str22.strip() \n",
    "str22.replace(\" \", \",\")\n",
    "print(str22)\n",
    "print(\"-------------=-=-=-=----------------\")\n",
    "data_lines = str22.splitlines()  # Split by newlines\n",
    "str22 = str(\"\\n\\n\\n Training accuracy:\\n\"  )\n",
    "data_lines += str22.splitlines()  # Split by newlines\n",
    "str22 = str(history.history['accuracy'])\n",
    "str22.strip() \n",
    "str22.replace(\" \", \",\")\n",
    "str22.replace(\"[\", \"\")\n",
    "str22.replace(\"]\", \"\")\n",
    "print(str22)\n",
    "print(\"-------------=-=-=-=----------------\")\n",
    "data_lines += str22.splitlines()  # Split by newlines\n",
    "\n",
    "print(data_lines)\n",
    "# Split each line into a list (comma-separated values)\n",
    "xlsFileData = [line.split(\",\") for line in data_lines]\n",
    "# Write the data to the worksheet, starting from row 1\n",
    "for row_index, row in enumerate(xlsFileData):\n",
    "    for col_index, value in enumerate(row):\n",
    "        ws.cell(row=row_index + 1, column=col_index + 1).value = value\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(csvPath)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training accuracy\n",
    "numberOfEpochs = epochs\n",
    "batchSizeOfTraining = batch_size\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], marker='o', linestyle='-', color='b')\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "picturePath = \"{}3.Model_training_Accuracy_{}_epoches_{}.png\".format(dataSetResultDirectory, dataSetName, numberOfEpochs)\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445/445 [==============================] - 4s 8ms/step - loss: 0.1505 - accuracy: 0.9544 - recall: 0.9827 - precision: 0.9300 - auc: 0.9846\n",
      "Test accuracy: 95.43889164924622\n",
      "Test recall: 98.27101230621338\n",
      "Test precision: 93.00252795219421\n",
      "Test AUC: 98.45583438873291\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the evaluate method\n",
    "y_test_float64 = np.asarray(y_test).astype('float64').reshape((-1,1))  #data['CoronaryHeartDisease']\n",
    "model2 = model\n",
    "loss2, accuracy, recall_value, precision_value, auc_value = model.evaluate(X_test_scaler, y_test_float64)\n",
    "\n",
    "# Print the results\n",
    "#print('Test loss: {}'.format(loss*100))\n",
    "print('Test accuracy: {}'.format(accuracy*100))\n",
    "print('Test recall: {}'.format(recall_value*100))\n",
    "print('Test precision: {}'.format(precision_value*100))\n",
    "print('Test AUC: {}'.format(auc_value*100))\n",
    "\n",
    "\n",
    "picturePath = \"{}Model_Evaluation_{}_{}_Epoch_{}.png\".format(dataSetResultDirectory, \"Testing_Accuracy\", dataSetName, numberOfEpochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (3896842879.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    546as\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "546as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954390914276107\n",
      "[0.         0.07392832 1.        ]\n",
      "[0.         0.98271015 1.        ]\n",
      "[inf  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, binary_predictions)\n",
    "# Calculate ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, binary_predictions)\n",
    "\n",
    "print(auc_score)\n",
    "print(fpr)\n",
    "print(tpr)\n",
    "print(_)\n",
    "\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(auc_score))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "picturePath = \"{}Model_Evaluation_ROC_{}_{}_Epoch_{}.png\".format(dataSetResultDirectory, method, dataSetName, numberOfEpochs)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'precision_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot Testing accuracy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set plot labels and title\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'precision_1'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Testing accuracy\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['precision_1'], label='Precision')\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.title('Training Evaluation Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics Value')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "picturePath = \"{}Model_Training_Evaluation_{}_{}_Epoch_{}.png\".format(dataSetResultDirectory, \"MLP\", dataSetName, numberOfEpochs)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "\n",
    "#plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features: 56913 -> Selected for SHAP:: 3983\n",
      "Total Test: 14229 -> Selected for SHAP:: 996\n",
      "testForShap: 996 -> Selected for Shape:: (996, 38), type:float32\n",
      "[ 52.     82.    114.     76.     68.1   172.4    22.91    6.     39.8\n",
      "   9.      1.5     0.7     4.45   12.6   238.     49.1    38.1    41.\n",
      "  93.     30.     49.      4.603  61.88    6.     23.8    75.      1.195\n",
      "   8.55   72.    243.9     2.021   4.45    0.8     5.6     1.      2.\n",
      "   2.      2.   ]\n"
     ]
    }
   ],
   "source": [
    "percentage = 0.07\n",
    "numberOfFeatures = int(len(features) *percentage)\n",
    "print(\"Total Features: {} -> Selected for SHAP:: {}\".format(len(features), numberOfFeatures))\n",
    "featuresForShap = X_train.columns #features[0:numberOfFeatures]\n",
    "#print(\" Features Name: {}\".format(  featuresForShap))\n",
    "\n",
    "numberOftest = int(len(X_test_f32) * percentage)\n",
    "print(\"Total Test: {} -> Selected for SHAP:: {}\".format(len(X_test_scaler), numberOftest))\n",
    "#testForShap = X_test_f32[0:len(featuresForShap)]\n",
    "testForShap = X_test_f32[0:numberOftest]\n",
    "#print(\" testForShap Name: {}\".format(  testForShap))\n",
    "print(\"testForShap: {} -> Selected for Shape:: {}, type:{}\".format(len(testForShap), testForShap.shape, testForShap.dtype))\n",
    "print(X_test_f32[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shap.DeepExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (14229, 38)   and dType: float32\n",
      "model shape: <keras.engine.functional.Functional object at 0x000002220BAA7D60>   and dType: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 243, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 26, in custom_record_gradient\n        out = tf_backprop._record_gradient(\"shap_\"+op_name, inputs, attrs, results)\n\n    AttributeError: Exception encountered when calling layer \"dense\" \"                 f\"(type Dense).\n    \n    module 'tensorflow.python.eager.backprop' has no attribute '_record_gradient'\n    \n    Call arguments received by layer \"dense\" \"                 f\"(type Dense):\n       inputs=tf.Tensor(shape=(3984, 38), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m deepExplainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, X_test_f32[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mint\u001b[39m(numberOftest\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n\u001b[0;32m      5\u001b[0m deepTestValues \u001b[38;5;241m=\u001b[39m  testForShap \u001b[38;5;66;03m#[0:int(numberOftest)] \u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m deepShap_values \u001b[38;5;241m=\u001b[39m \u001b[43mdeepExplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepTestValues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m        were chosen as \"top\".\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:308\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    307\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j,i]\n\u001b[1;32m--> 308\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi_symbolic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:365\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[1;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[0;32m    362\u001b[0m     tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39m_record_gradient\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_out\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_with_overridden_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43manon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:401\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf_gradients_impl, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_IsBackpropagatable\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:361\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[1;34m()\u001b[0m\n\u001b[0;32m    359\u001b[0m     v \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs[i]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    360\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m--> 361\u001b[0m final_out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m tf_execute\u001b[38;5;241m.\u001b[39mrecord_gradient \u001b[38;5;241m=\u001b[39m tf_backprop\u001b[38;5;241m.\u001b[39m_record_gradient\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_out\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\MUBASH~1\\AppData\\Local\\Temp\\__autograph_generated_fileet4ycmfa.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__grad_graph\u001b[1;34m(shap_rAnD)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape(watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     15\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mwatch, (ag__\u001b[38;5;241m.\u001b[39mld(shap_rAnD),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_rAnD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (out,)\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:26\u001b[0m, in \u001b[0;36mcustom_record_gradient\u001b[1;34m(op_name, inputs, attrs, results)\u001b[0m\n\u001b[0;32m     24\u001b[0m     inputs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m     25\u001b[0m     reset_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtf_backprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_gradient\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshap_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mop_name, inputs, attrs, results)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_input:\n\u001b[0;32m     29\u001b[0m     inputs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint32\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 243, in grad_graph  *\n        out = self.model(shap_rAnD)\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Mubashir Iqbal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\", line 26, in custom_record_gradient\n        out = tf_backprop._record_gradient(\"shap_\"+op_name, inputs, attrs, results)\n\n    AttributeError: Exception encountered when calling layer \"dense\" \"                 f\"(type Dense).\n    \n    module 'tensorflow.python.eager.backprop' has no attribute '_record_gradient'\n    \n    Call arguments received by layer \"dense\" \"                 f\"(type Dense):\n       inputs=tf.Tensor(shape=(3984, 38), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"features shape: {}   and dType: {}\".format(X_test_f32.shape, X_test_f32.dtype)) \n",
    "print(\"model shape: {}   and dType: {}\".format(model, model.dtype)) \n",
    "\n",
    "deepExplainer = shap.DeepExplainer(model, X_test_f32[0:int(numberOftest*2)])\n",
    "deepTestValues =  testForShap #[0:int(numberOftest)] \n",
    "deepShap_values = deepExplainer.shap_values(deepTestValues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepShap_array = np.array(deepShap_values) \n",
    "mean_abs_shap_values = np.mean(np.abs(deepShap_array), axis=(0, 1)) \n",
    "sorted_indices = np.argsort(mean_abs_shap_values)[::-1] \n",
    "sorted_feature_names = np.array(X.columns.to_list())[sorted_indices]\n",
    "\n",
    "sorted_shap_values = deepShap_array[:, sorted_indices].T\n",
    "#print(sorted_shap_values) \n",
    "deepShapValuesPlot = mean_abs_shap_values[sorted_indices]\n",
    "\n",
    "str22 = 0\n",
    "csvPath = \"{}Model_SHAP_DeepExplainer_FeatureRanking_{}_{}_Epoch_{}.xlsx\".format(dataSetResultDirectory, method, dataSetName, numberOfEpochs)\n",
    "str22 = str(\"DeepExplainer Top Feature List\\n\")\n",
    "indexx = 1\n",
    "for feature, mean_shap_value in zip(sorted_feature_names, mean_abs_shap_values[sorted_indices]):\n",
    "        str22 += str(f\"{indexx}, {feature}, {mean_shap_value} \\n\") \n",
    "        indexx += 1\n",
    "\n",
    "# Create a new workbook\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active  # Get the active worksheet\n",
    "data_lines = str22.splitlines()  # Split by newlines\n",
    " \n",
    "# Split each line into a list (comma-separated values)\n",
    "xlsFileData = [line.split(\",\") for line in data_lines] \n",
    "for row_index, row in enumerate(xlsFileData):\n",
    "    for col_index, value in enumerate(row):\n",
    "        ws.cell(row=row_index + 1, column=col_index + 1).value = value\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(csvPath)\n",
    "\n",
    "print(\"DeepExplainer Top Feature List\")\n",
    "print(\"--------------------------------\")\n",
    "for feature, mean_shap_value in zip(sorted_feature_names, mean_abs_shap_values[sorted_indices]):\n",
    "    print(f\"{feature}, {mean_shap_value}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(deepShap_values, deepTestValues, feature_names=featuresForShap, show=False)\n",
    "ax = mplot.gca() \n",
    "ax.set_title(\"XAI SHAP DeepExplainer\" ,fontsize=16, fontweight='bold')     \n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of SHAP dataset: {}\".format(len(testForShap))\n",
    "ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer_{}_{}_Sorted_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.show()\n",
    "#os.startfile(picturePath)\n",
    "mplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample for explanation (adjust index as needed)\n",
    "sample_to_explain = testForShap[0]  # Choose the first sample in the test set for illustration\n",
    "print(sample_to_explain)\n",
    "# Explain the sample using SHAP\n",
    "shap_values = deepExplainer.shap_values(sample_to_explain[np.newaxis, ...])\n",
    "\n",
    "# Create SHAP Waterfall plot\n",
    "shap.waterfall_plot(shap_values, sample_to_explain[np.newaxis, ...], feature_names=featuresForShap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_to_explain = testForShap[0]  # Choose the first sample in the test set for illustration\n",
    "print(sample_to_explain)\n",
    "# Explain the sample using SHAP\n",
    "shap_values = deepExplainer.shap_values(sample_to_explain[np.newaxis, ...])\n",
    "\n",
    "# Create the waterfall plot\n",
    "shap.waterfall_plot(shap_values, sample_to_explain[np.newaxis, ...])\n",
    "\n",
    "# Get the current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set x-axis tick labels (assuming featuresForShap is a list of feature names)\n",
    "ax.set_xticks(np.arange(len(featuresForShap)))\n",
    "ax.set_xticklabels(featuresForShap, rotation=45, ha='right')\n",
    "\n",
    "# Adjust layout to accommodate labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howManyFeatures = 15\n",
    "# Calculate feature importance based on the mean absolute SHAP values\n",
    "feature_importance =  np.abs(deepShap_values).mean(axis=(0, 1))\n",
    "top_features_indices = np.argsort(feature_importance)[::-1][:howManyFeatures]\n",
    "# Select only the top features and corresponding SHAP values\n",
    "print(top_features_indices)\n",
    "featureNamesSHAP = X.columns[top_features_indices]\n",
    "top_features = testForShap[:, top_features_indices]\n",
    "top_shap_values = deepShap_values[0][:, top_features_indices]\n",
    "\n",
    "print(\"\\n--------------------------------------------------\") \n",
    "print(\"Top SHAP Explainer values:\")\n",
    "for i in range(len(top_features_indices)):\n",
    "    feature_index = top_features_indices[i]\n",
    "    feature_name = X.columns[feature_index]\n",
    "    shap_value = np.mean(np.abs(top_shap_values[:, i])) \n",
    "    print(f\"{feature_name}, {shap_value}\")\n",
    " \n",
    "print(\"--------------------------------------------------\\n\") \n",
    " \n",
    "\n",
    "# Plot the summary plot for the top 15 features\n",
    "shap.summary_plot(top_shap_values, top_features, feature_names=featureNamesSHAP, show=False)\n",
    "ax = mplot.gca() \n",
    "ax.set_title(\"XAI SHAP DeeppExplainer Sorted  ({} Features)\".format(howManyFeatures) ,fontsize=16, fontweight='bold')     \n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of SHAP dataset: {}\".format(len(testForShap)) \n",
    "ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_Bar_{}_{}_Sorted_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "mplot.show()\n",
    "#os.startfile(picturePath)\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist() \n",
    " \n",
    "top_10_feature_names = [feature_names[i] for i in top_features_indices]\n",
    "top_10_shap_values = deepShap_values[0][:, top_features_indices] \n",
    "# Create a DataFrame for visualization\n",
    "df_top_10 = pd.DataFrame(data=top_10_shap_values, columns=top_10_feature_names)\n",
    "# Plotting with Seaborn's violinplot\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.violinplot(data=df_top_10, inner=\"quartile\", palette=\"muted\") \n",
    "plt.title('SHAP (DeepExplainer) Violin Plot')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_SNS_Violinplot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight') \n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plotting a Bubble Chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, feature in enumerate(top_10_feature_names):\n",
    "    size = np.abs(df_top_10[feature]) * 100  # Adjust the scale as needed\n",
    "    plt.scatter(x=[i] * len(df_top_10), y=df_top_10[feature], s=size, label=feature, alpha=0.6)\n",
    " \n",
    "plt.title('SHAP (DeepExplainer) Bubble Chart')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('SHAP Values')\n",
    "plt.xticks(range(len(top_10_feature_names)), top_10_feature_names, rotation=45, ha='right')\n",
    "#plt.legend()\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_SNS_BubbleChart_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Bubble Chart   \n",
    "top_10_avg_shap_values = feature_importance[top_features_indices]\n",
    "\n",
    "# Calculate the scale for bubble size based on the average values compared to others\n",
    "size_scale = np.abs(top_10_avg_shap_values) / np.max(np.abs(top_10_avg_shap_values))\n",
    "# Create a DataFrame for visualization\n",
    "df_top_10_avg_shap = pd.DataFrame({'Feature': top_10_feature_names, 'Average SHAP Value': top_10_avg_shap_values})\n",
    "# Plotting a Bubble Chart for top 10 average SHAP values\n",
    "plt.figure(figsize=(12, 6))\n",
    "size = size_scale * 1000  # Adjust the scale as needed\n",
    "plt.scatter(x=range(len(df_top_10_avg_shap)), y=df_top_10_avg_shap['Average SHAP Value'], s=size, alpha=0.6)\n",
    "\n",
    "plt.title('SHAP (DeepExplainer) Bubble Chart Average')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Average SHAP Values')\n",
    "plt.xticks(range(len(df_top_10_avg_shap)), df_top_10_avg_shap['Feature'], rotation=45, ha='right')\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_SNS_BubbleChartAverage_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plotting a boxplot for the top 10 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_axis_range = (-0.10, 0.10)  # Adjust the range as needed\n",
    "sns.boxplot(data=df_top_10, orient='v', palette='Set2')\n",
    "plt.title('SHAP (DeepExplainer) Box Plot')\n",
    "plt.xlabel('SHAP Values')\n",
    "plt.ylabel('Features')\n",
    "plt.xticks(range(len(df_top_10_avg_shap)), df_top_10_avg_shap['Feature'], rotation=45, ha='right')\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_SNS_BoxPlot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 #  swarmplot (Beeswarm plot)\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.swarmplot(data=df_top_10, palette=\"muted\", size=3) \n",
    "plt.title('SHAP (DeepExplainer) Beeswarm Plot')\n",
    "plt.ylabel('SHAP Values')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_DeepExplainer2_SNS_Beeswarmplot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shap.Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = shap.Explainer(model, feature_names=featuresForShap, masker=shap.maskers.Independent(data=testForShap)) \n",
    "\n",
    "shap_values = shap_explainer.shap_values(testForShap)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance based on the mean absolute SHAP values\n",
    "feature_names = X.columns.tolist()\n",
    "# Calculate average SHAP values across all instances\n",
    "avg_shap_values = np.mean(shap_values, axis=0) \n",
    " \n",
    "# Calculate feature importance based on the mean absolute SHAP values\n",
    "feature_importance =  np.abs(shap_values).mean(axis=0)\n",
    "top_features_indices = np.argsort(feature_importance)[::-1][:howManyFeatures]\n",
    "# Select only the top features and corresponding SHAP values\n",
    "print(top_features_indices)\n",
    "featureNamesSHAP = X.columns[top_features_indices]\n",
    "top_features = testForShap[:, top_features_indices]\n",
    "top_shap_values = shap_values[:, top_features_indices]\n",
    "\n",
    "\n",
    "csvPath = \"{}Model_SHAP_KernelExplainer_FeatureRanking_{}_{}_Epoch_{}.csv\".format(dataSetResultDirectory, method, dataSetName, numberOfEpochs)\n",
    "with open(csvPath, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(\"KernalExplainer Top Feature List\")\n",
    "    for i in range(len(top_features_indices)):\n",
    "        feature_index = top_features_indices[i]\n",
    "        feature_name = feature_names[feature_index]\n",
    "        shap_value = np.mean(np.abs(top_shap_values[:, i])) \n",
    "        writer.writerows(f\"{feature_name}, {shap_value} \\n\") \n",
    "\n",
    "\n",
    "print(\"\\n\\n--------------------------------------------------\") \n",
    "print(\"Top SHAP Explainer values:\")\n",
    "for i in range(len(top_features_indices)):\n",
    "    feature_index = top_features_indices[i]\n",
    "    feature_name = feature_names[feature_index]\n",
    "    shap_value = np.mean(np.abs(top_shap_values[:, i])) \n",
    "    print(f\"{feature_name}, {shap_value}\")\n",
    " \n",
    " \n",
    "\n",
    "# Plot the summary plot for the top 15 features\n",
    "shap.summary_plot(top_shap_values, top_features, feature_names=featureNamesSHAP, plot_type=\"bar\", show=False)\n",
    "ax = mplot.gca() \n",
    "ax.set_title(\"XAI SHAP Explainer Sorted  ({} Features)\".format(howManyFeatures) ,fontsize=16, fontweight='bold')     \n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of SHAP dataset: {}\".format(len(testForShap))\n",
    "shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_Bar_{}_{}_Sorted_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.show()\n",
    "#os.startfile(picturePath)\n",
    "mplot.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the summary plot for the top 15 features\n",
    "shap.summary_plot(top_shap_values, top_features, feature_names=featureNamesSHAP, show=False)\n",
    "ax = mplot.gca() \n",
    "ax.set_title(\"XAI SHAP Explainer Sorted  ({} Features)\".format(howManyFeatures) ,fontsize=16, fontweight='bold')     \n",
    "dataSetString = \"Dataset:  {}\".format(dataSetName)\n",
    "testingDatasetString =\"length of SHAP dataset: {}\".format(len(testForShap))\n",
    "shapTypeString =\"SHAP Type: {}\".format(repr(shap_explainer)) \n",
    "ax.figure.text(0.020, -0.05,  dataSetString, horizontalalignment='left', wrap=False )  \n",
    "ax.figure.text(0.020, -0.09,  testingDatasetString, horizontalalignment='left', wrap=False )   \n",
    "ax.figure.text(0.020, -0.13,  shapTypeString, horizontalalignment='left', wrap=False )   \n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_Bar_{}_{}_Sorted_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.show()\n",
    "#os.startfile(picturePath)\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist() \n",
    " \n",
    "\n",
    "top_10_feature_names = [feature_names[i] for i in top_features_indices]\n",
    "top_10_shap_values = shap_values[:, top_features_indices] \n",
    "# Create a DataFrame for visualization\n",
    "df_top_10 = pd.DataFrame(data=top_10_shap_values, columns=top_10_feature_names)\n",
    "# Plotting with Seaborn's violinplot\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.violinplot(data=df_top_10, inner=\"quartile\", palette=\"muted\") \n",
    "plt.title('MLP Model with SHAP (XAI) Violin Plot')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_Violinplot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight') \n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Bubble Chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, feature in enumerate(top_10_feature_names):\n",
    "    size = np.abs(df_top_10[feature]) * 100  # Adjust the scale as needed\n",
    "    plt.scatter(x=[i] * len(df_top_10), y=df_top_10[feature], s=size, label=feature, alpha=0.6)\n",
    " \n",
    "plt.title('MLP Model with SHAP (XAI) Bubble Chart')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('SHAP Values')\n",
    "plt.xticks(range(len(top_10_feature_names)), top_10_feature_names, rotation=45, ha='right')\n",
    "#plt.legend()\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_BubbleChart_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bubble Chart \n",
    "top_10_feature_names = [feature_names[i] for i in top_features_indices]\n",
    "top_10_avg_shap_values = avg_shap_values[top_features_indices]\n",
    "\n",
    "# Calculate the scale for bubble size based on the average values compared to others\n",
    "size_scale = np.abs(top_10_avg_shap_values) / np.max(np.abs(top_10_avg_shap_values))\n",
    "# Create a DataFrame for visualization\n",
    "df_top_10_avg_shap = pd.DataFrame({'Feature': top_10_feature_names, 'Average SHAP Value': top_10_avg_shap_values})\n",
    "# Plotting a Bubble Chart for top 10 average SHAP values\n",
    "plt.figure(figsize=(12, 6))\n",
    "size = size_scale * 1000  # Adjust the scale as needed\n",
    "plt.scatter(x=range(len(df_top_10_avg_shap)), y=df_top_10_avg_shap['Average SHAP Value'], s=size, alpha=0.6)\n",
    "\n",
    "plt.title('MLP Model with SHAP (XAI) Bubble Chart Average')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Average SHAP Values')\n",
    "plt.xticks(range(len(df_top_10_avg_shap)), df_top_10_avg_shap['Feature'], rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_BubbleChartAverage_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a boxplot for the top 10 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "x_axis_range = (-0.10, 0.10)  # Adjust the range as needed\n",
    "sns.boxplot(data=df_top_10, orient='v', palette='Set2')\n",
    "plt.title('MLP Model with SHAP (XAI) Box Plot')\n",
    "plt.xlabel('SHAP Values')\n",
    "plt.ylabel('Features')\n",
    "plt.xticks(range(len(df_top_10_avg_shap)), df_top_10_avg_shap['Feature'], rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_BoxPlot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting an area chart for all SHAP values of the top 10 features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for feature in top_10_feature_names:\n",
    "    sns.lineplot(x=range(df_top_10.shape[0]), y=df_top_10[feature], label=feature)\n",
    " \n",
    "plt.title('MLP Model with SHAP (XAI) Area Chart')\n",
    "\n",
    "plt.xlabel('Instances')\n",
    "plt.ylabel('SHAP Values')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_AreaChart_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "currentDateTime = datetime.datetime.now() \n",
    "currentDateTime = currentDateTime.strftime(\"%Y%m%d_%H%M\") \n",
    "modelPath = \"{}model_trained_{}_{}_{}percent.model\".format(dataSetResultDirectory, dataSetName, currentDateTime, accuracy)\n",
    "print(modelPath)\n",
    "model.save(modelPath)\n",
    "\n",
    "\n",
    "explainerPath = \"{}ShapeExplainer_{}_{:.2f}percent.pkl\".format(dataSetResultDirectory, currentDateTime, (accuracy*100))\n",
    "print(explainerPath)\n",
    "\n",
    "explainerValuePath = \"{}ShapeExplainerValues_{}_{:.2f}percent.pkl\".format(dataSetResultDirectory, currentDateTime, (accuracy*100))\n",
    "print(explainerValuePath)\n",
    "  \n",
    "# Save the SHAP values to a file using pickle\n",
    "with open(explainerValuePath, 'wb') as shap_values_file:\n",
    "    pickle.dump(shap_values, shap_values_file)\n",
    "\n",
    "\n",
    "# Save the SHAP values to a file using pickle\n",
    "with open(explainerPath, 'wb') as explainer_file:\n",
    "    pickle.dump(shap_explainer, explainer_file)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  swarmplot (Beeswarm plot)\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.swarmplot(data=df_top_10, palette=\"muted\", size=3) \n",
    "plt.title('MLP Model with SHAP (XAI) Beeswarm Plot')\n",
    "plt.ylabel('SHAP Values')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "picturePath = \"{}XAI_SHAP_Explainer_SNS_Beeswarmplot_{}_{}_numberOfSamples_{}.png\".format(dataSetResultDirectory, method, dataSetName, len(testForShap))\n",
    "plt.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
